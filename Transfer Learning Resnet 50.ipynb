{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning VGG 16 and VGG 19 using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please download the dataset from the below url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries as shown below\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = 'Datasets/train'\n",
    "valid_path = 'Datasets/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG\n",
    "# Here we will be using imagenet weights\n",
    "\n",
    "resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # useful for getting number of output classes\n",
    "folders = glob('Datasets/Train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(resnet.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=resnet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            301059      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,888,771\n",
      "Trainable params: 301,059\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# view the structure of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image Data Generator to import the images from the dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory('Datasets/Train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('Datasets/Test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-69229fe26ea3>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 2 steps, validate for 2 steps\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 22s 11s/step - loss: 5.5148 - accuracy: 0.4219 - val_loss: 11.6715 - val_accuracy: 0.3276\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 18s 9s/step - loss: 5.5461 - accuracy: 0.5938 - val_loss: 8.1051 - val_accuracy: 0.3276\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 16s 8s/step - loss: 2.2380 - accuracy: 0.7812 - val_loss: 10.3394 - val_accuracy: 0.3276\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.5702 - accuracy: 0.9531 - val_loss: 13.5645 - val_accuracy: 0.3276\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 15s 8s/step - loss: 0.2554 - accuracy: 0.9688 - val_loss: 16.6514 - val_accuracy: 0.3276\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.5786 - accuracy: 0.9531 - val_loss: 18.7570 - val_accuracy: 0.3276\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.1028 - accuracy: 0.9844 - val_loss: 20.7876 - val_accuracy: 0.3276\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 15s 8s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 22.4275 - val_accuracy: 0.3276\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 15s 8s/step - loss: 0.3081 - accuracy: 0.9531 - val_loss: 23.1395 - val_accuracy: 0.3276\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 15s 8s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 23.4435 - val_accuracy: 0.3276\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 16s 8s/step - loss: 8.3113e-06 - accuracy: 1.0000 - val_loss: 23.6919 - val_accuracy: 0.3276\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 16s 8s/step - loss: 4.4139e-04 - accuracy: 1.0000 - val_loss: 23.8723 - val_accuracy: 0.3276\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 16s 8s/step - loss: 7.0555e-04 - accuracy: 1.0000 - val_loss: 24.0033 - val_accuracy: 0.3276\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 17s 8s/step - loss: 9.3132e-09 - accuracy: 1.0000 - val_loss: 24.0951 - val_accuracy: 0.3276\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 17s 8s/step - loss: 1.7042e-06 - accuracy: 1.0000 - val_loss: 24.1712 - val_accuracy: 0.3276\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 24.2342 - val_accuracy: 0.3276\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 17s 8s/step - loss: 9.1081e-07 - accuracy: 1.0000 - val_loss: 24.2866 - val_accuracy: 0.3276\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 16s 8s/step - loss: 3.8370e-07 - accuracy: 1.0000 - val_loss: 24.3300 - val_accuracy: 0.3276\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 17s 9s/step - loss: 3.7931e-05 - accuracy: 1.0000 - val_loss: 24.3681 - val_accuracy: 0.3276\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 19s 9s/step - loss: 1.8626e-09 - accuracy: 1.0000 - val_loss: 24.3996 - val_accuracy: 0.3276\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 19s 9s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 24.4258 - val_accuracy: 0.3276\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 19s 9s/step - loss: 0.0602 - accuracy: 0.9844 - val_loss: 24.0821 - val_accuracy: 0.3276\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 18s 9s/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 23.4656 - val_accuracy: 0.3276\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 18s 9s/step - loss: 7.9533e-07 - accuracy: 1.0000 - val_loss: 22.9560 - val_accuracy: 0.3276\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 19s 9s/step - loss: 8.9963e-07 - accuracy: 1.0000 - val_loss: 22.5350 - val_accuracy: 0.3276\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 18s 9s/step - loss: 0.2801 - accuracy: 0.9844 - val_loss: 22.5433 - val_accuracy: 0.3276\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 16s 8s/step - loss: 2.1419e-06 - accuracy: 1.0000 - val_loss: 22.8735 - val_accuracy: 0.3276\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.0566 - accuracy: 0.9844 - val_loss: 23.9851 - val_accuracy: 0.3276\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 16s 8s/step - loss: 1.8626e-09 - accuracy: 1.0000 - val_loss: 24.9016 - val_accuracy: 0.3276\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 15s 8s/step - loss: 8.0094e-08 - accuracy: 1.0000 - val_loss: 25.6567 - val_accuracy: 0.3276\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 15s 8s/step - loss: 7.3573e-07 - accuracy: 1.0000 - val_loss: 26.2788 - val_accuracy: 0.3276\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 15s 8s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.7909 - val_accuracy: 0.3276\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 15s 8s/step - loss: 1.3039e-08 - accuracy: 1.0000 - val_loss: 27.2123 - val_accuracy: 0.3276\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 15s 8s/step - loss: 1.3398e-04 - accuracy: 1.0000 - val_loss: 27.5530 - val_accuracy: 0.3276\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 15s 8s/step - loss: 1.8216e-06 - accuracy: 1.0000 - val_loss: 27.8330 - val_accuracy: 0.3276\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 15s 8s/step - loss: 0.1636 - accuracy: 0.9844 - val_loss: 27.8716 - val_accuracy: 0.3276\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 16s 8s/step - loss: 3.8929e-07 - accuracy: 1.0000 - val_loss: 27.7295 - val_accuracy: 0.3276\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 17s 9s/step - loss: 6.5662e-05 - accuracy: 1.0000 - val_loss: 27.6089 - val_accuracy: 0.3276\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 17s 8s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.5099 - val_accuracy: 0.3276\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 20s 10s/step - loss: 9.0312e-06 - accuracy: 1.0000 - val_loss: 27.4278 - val_accuracy: 0.3276\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 27s 13s/step - loss: 5.5879e-09 - accuracy: 1.0000 - val_loss: 27.3604 - val_accuracy: 0.3276\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 26s 13s/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 27.3052 - val_accuracy: 0.3276\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 26s 13s/step - loss: 2.2352e-08 - accuracy: 1.0000 - val_loss: 27.2599 - val_accuracy: 0.3276\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 26s 13s/step - loss: 1.8626e-09 - accuracy: 1.0000 - val_loss: 27.2227 - val_accuracy: 0.3276\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 27s 14s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 27.1923 - val_accuracy: 0.3276\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 27s 13s/step - loss: 7.4506e-09 - accuracy: 1.0000 - val_loss: 27.1673 - val_accuracy: 0.3276\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 26s 13s/step - loss: 3.3528e-08 - accuracy: 1.0000 - val_loss: 27.1469 - val_accuracy: 0.3276\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 25s 12s/step - loss: 5.9605e-08 - accuracy: 1.0000 - val_loss: 27.1302 - val_accuracy: 0.3276\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 25s 13s/step - loss: 1.7903e-05 - accuracy: 1.0000 - val_loss: 27.1152 - val_accuracy: 0.3276\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 26s 13s/step - loss: 2.7940e-08 - accuracy: 1.0000 - val_loss: 27.1029 - val_accuracy: 0.3276\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "# Run the cell. It will take some time to execute\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=50,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a h5 file\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('model_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1098703e-17, 7.0626823e-18, 1.0000000e+00],\n",
       "       [5.4012853e-17, 3.8939481e-17, 1.0000000e+00],\n",
       "       [3.0164312e-19, 1.5276618e-19, 1.0000000e+00],\n",
       "       [8.1685128e-18, 2.1057049e-18, 1.0000000e+00],\n",
       "       [6.5968696e-18, 2.6956530e-18, 1.0000000e+00],\n",
       "       [3.7833818e-18, 1.2350878e-18, 1.0000000e+00],\n",
       "       [1.1129351e-18, 2.3423726e-18, 1.0000000e+00],\n",
       "       [7.4068242e-18, 2.1298031e-18, 1.0000000e+00],\n",
       "       [6.7320127e-18, 3.2536628e-18, 1.0000000e+00],\n",
       "       [2.8936134e-18, 6.1215486e-19, 1.0000000e+00],\n",
       "       [1.4505833e-18, 8.5016538e-19, 1.0000000e+00],\n",
       "       [7.0507568e-18, 1.3733323e-18, 1.0000000e+00],\n",
       "       [5.3826880e-18, 4.8261886e-18, 1.0000000e+00],\n",
       "       [5.6449023e-19, 6.0742814e-19, 1.0000000e+00],\n",
       "       [4.7418778e-18, 1.4848299e-18, 1.0000000e+00],\n",
       "       [1.6203128e-17, 3.8341612e-18, 1.0000000e+00],\n",
       "       [3.1620372e-19, 6.0217715e-19, 1.0000000e+00],\n",
       "       [5.0942606e-19, 4.7927036e-19, 1.0000000e+00],\n",
       "       [7.5867496e-19, 4.6131439e-19, 1.0000000e+00],\n",
       "       [5.9412061e-18, 2.5823468e-18, 1.0000000e+00],\n",
       "       [2.5323804e-18, 6.5646584e-19, 1.0000000e+00],\n",
       "       [9.2142858e-18, 7.6224644e-18, 1.0000000e+00],\n",
       "       [7.6097680e-18, 6.2844334e-19, 1.0000000e+00],\n",
       "       [9.4632461e-19, 4.4321547e-19, 1.0000000e+00],\n",
       "       [1.7840373e-18, 1.0950539e-18, 1.0000000e+00],\n",
       "       [2.8265526e-17, 1.0868062e-17, 1.0000000e+00],\n",
       "       [4.2587712e-18, 1.6899432e-18, 1.0000000e+00],\n",
       "       [4.5419900e-18, 1.7330708e-18, 1.0000000e+00],\n",
       "       [2.2409309e-17, 6.0130968e-18, 1.0000000e+00],\n",
       "       [5.5124616e-17, 1.3817726e-17, 1.0000000e+00],\n",
       "       [4.2562541e-18, 4.2512236e-18, 1.0000000e+00],\n",
       "       [6.4947156e-19, 7.3563317e-19, 1.0000000e+00],\n",
       "       [2.9965445e-19, 2.2999855e-19, 1.0000000e+00],\n",
       "       [5.7799636e-17, 1.6073171e-17, 1.0000000e+00],\n",
       "       [4.4084822e-18, 2.4926819e-18, 1.0000000e+00],\n",
       "       [1.5315136e-18, 8.2273958e-19, 1.0000000e+00],\n",
       "       [4.3013709e-17, 2.2873531e-17, 1.0000000e+00],\n",
       "       [7.1786347e-19, 1.5773342e-19, 1.0000000e+00],\n",
       "       [1.9118762e-18, 6.2969119e-19, 1.0000000e+00],\n",
       "       [4.5249902e-18, 5.9956892e-18, 1.0000000e+00],\n",
       "       [3.9477451e-18, 1.3443880e-18, 1.0000000e+00],\n",
       "       [8.5476762e-17, 1.9186208e-17, 1.0000000e+00],\n",
       "       [1.7967269e-18, 1.5220434e-18, 1.0000000e+00],\n",
       "       [1.7870137e-18, 2.3225831e-19, 1.0000000e+00],\n",
       "       [4.6285121e-20, 9.3102732e-20, 1.0000000e+00],\n",
       "       [2.0382892e-18, 3.2499540e-18, 1.0000000e+00],\n",
       "       [9.1842070e-19, 7.6164144e-19, 1.0000000e+00],\n",
       "       [6.1118721e-17, 1.0889019e-17, 1.0000000e+00],\n",
       "       [5.9787196e-18, 2.8902596e-18, 1.0000000e+00],\n",
       "       [4.9778090e-19, 1.0570318e-17, 1.0000000e+00],\n",
       "       [1.8776171e-18, 6.9687196e-18, 1.0000000e+00],\n",
       "       [1.0696549e-17, 8.7897841e-18, 1.0000000e+00],\n",
       "       [1.6884795e-19, 1.3699358e-19, 1.0000000e+00],\n",
       "       [5.9673081e-17, 9.1768220e-18, 1.0000000e+00],\n",
       "       [3.3356660e-18, 9.5707785e-19, 1.0000000e+00],\n",
       "       [1.2171698e-17, 9.7396530e-18, 1.0000000e+00],\n",
       "       [5.7131860e-19, 1.0752099e-18, 1.0000000e+00],\n",
       "       [4.7271043e-18, 1.2285655e-18, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('model_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-7b8301fa3f5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'img_data' is not defined"
     ]
    }
   ],
   "source": [
    "img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img('Datasets/Test/lamborghini/11.jpg',target_size=(224,224))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [196., 187., 172.],\n",
       "        [217., 208., 193.],\n",
       "        [243., 234., 219.]],\n",
       "\n",
       "       [[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [245., 245., 237.],\n",
       "        [243., 243., 235.],\n",
       "        [242., 242., 234.]],\n",
       "\n",
       "       [[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [240., 249., 248.],\n",
       "        [242., 251., 250.],\n",
       "        [242., 251., 250.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[189., 207., 229.],\n",
       "        [190., 206., 229.],\n",
       "        [190., 206., 229.],\n",
       "        ...,\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]],\n",
       "\n",
       "       [[185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        ...,\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]],\n",
       "\n",
       "       [[185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        ...,\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=image.img_to_array(img)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.expand_dims(x,axis=0)\n",
    "img_data=preprocess_input(x)\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.3902892e-11, 2.0502819e-08, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.argmax(model.predict(img_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
